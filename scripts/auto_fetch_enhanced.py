#!/usr/bin/env python3
"""
å…¨è‡ªåŠ¨æ›´æ–°è„šæœ¬ - ç¡®ä¿æ¯ä¸ªåˆ†ç±»è‡³å°‘2ç¯‡æ–‡ç« 
è‡ªåŠ¨æŠ“å–RSS + ç”Ÿæˆä¸­æ–‡åˆ†æ + æ›´æ–°çŸ¥è¯†åº“ + åˆ†ç±»å‡è¡¡
"""

import json
import feedparser
import hashlib
import os
import re
from datetime import datetime, timedelta

WORKSPACE = "."
SOURCES_FILE = f"{WORKSPACE}/data/sources.json"
ARTICLES_FILE = f"{WORKSPACE}/data/articles.json"
KB_FILE = f"{WORKSPACE}/knowledge-base.js"

CATEGORY_CONFIG = {
    "ue": {"name": "Unreal Engine", "color": "#00f0ff"},
    "ta": {"name": "æŠ€æœ¯ç¾æœ¯", "color": "#b026ff"},
    "render": {"name": "å®æ—¶æ¸²æŸ“", "color": "#ffbe0b"},
    "ta-render": {"name": "TAæ¸²æŸ“ä¸“æ ", "color": "#00ff88"},
    "ai": {"name": "AIæŠ€æœ¯", "color": "#ff006e"}
}

def load_sources():
    with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_existing_articles():
    if os.path.exists(ARTICLES_FILE):
        with open(ARTICLES_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_articles(articles):
    with open(ARTICLES_FILE, 'w', encoding='utf-8') as f:
        json.dump(articles, f, ensure_ascii=False, indent=2)

def generate_article_id(url):
    return hashlib.md5(url.encode()).hexdigest()[:12]

def clean_html(text):
    if not text:
        return ""
    text = re.sub(r'<[^>]+>', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def parse_date(date_str):
    """è§£æå„ç§æ—¥æœŸæ ¼å¼"""
    formats = [
        '%a, %d %b %Y %H:%M:%S %z',
        '%Y-%m-%dT%H:%M:%S%z',
        '%Y-%m-%d %H:%M:%S',
        '%Y-%m-%d'
    ]
    for fmt in formats:
        try:
            return datetime.strptime(date_str[:26], fmt)
        except:
            continue
    return datetime.now()

def should_include_article(article, settings, existing_ids):
    """è¿‡æ»¤æ–‡ç« """
    if article['id'] in existing_ids:
        return False
    
    title = article.get('title', '').lower()
    summary = article.get('summary', '').lower()
    
    # æ’é™¤Unityæ–‡ç« 
    exclude_keywords = settings.get('exclude_keywords', [])
    for keyword in exclude_keywords:
        if keyword.lower() in title or keyword.lower() in summary:
            print(f"    â­ï¸  è·³è¿‡(Unity): {article['title'][:50]}...")
            return False
    
    # æ£€æµ‹UEç›¸å…³å†…å®¹å¹¶è‡ªåŠ¨åˆ†ç±»
    ue_keywords = ['unreal', 'ue5', 'ue4', 'niagara', 'lumen', 'nanite', 'epic games']
    if any(kw in title.lower() or kw in summary.lower() for kw in ue_keywords):
        if article['category'] != 'ue':
            article['category'] = 'ue'
            print(f"    â­ è‡ªåŠ¨å½’ç±»ä¸ºUE: {article['title'][:40]}...")
    
    # æ£€æµ‹AIç›¸å…³å†…å®¹
    ai_keywords = ['ai ', 'artificial intelligence', 'machine learning', 'neural', 'deep learning', 'generative', 'gpt', 'llm']
    if any(kw in title.lower() or kw in summary.lower() for kw in ai_keywords):
        if article['category'] != 'ai':
            article['category'] = 'ai'
            print(f"    ğŸ¤– è‡ªåŠ¨å½’ç±»ä¸ºAI: {article['title'][:40]}...")
    
    # æ£€æµ‹æ¸²æŸ“ç›¸å…³å†…å®¹
    render_keywords = ['rendering', 'ray tracing', 'global illumination', 'pbr', 'shader', 'graphics']
    if any(kw in title.lower() or kw in summary.lower() for kw in render_keywords):
        if article['category'] not in ['render', 'ta-render']:
            article['category'] = 'render'
            print(f"    ğŸ¨ è‡ªåŠ¨å½’ç±»ä¸ºæ¸²æŸ“: {article['title'][:40]}...")
    
    return True

def is_recent_article(article, days_back=3):
    """æ£€æŸ¥æ–‡ç« æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•°å†…"""
    try:
        pub_date = parse_date(article.get('published', ''))
        cutoff = datetime.now() - timedelta(days=days_back)
        return pub_date >= cutoff
    except:
        return True  # å¦‚æœè§£æå¤±è´¥ï¼Œé»˜è®¤ä¿ç•™

def generate_analysis(article, category):
    """ç”Ÿæˆæ–‡ç« åˆ†æ"""
    title = article['title']
    summary = clean_html(article.get('summary', ''))
    
    # æ ‡é¢˜ç¿»è¯‘
    translations = {
        'Unreal Engine': 'è™šå¹»å¼•æ“',
        'UE5': 'UE5',
        'UE4': 'UE4',
        'Nanite': 'Nanite',
        'Lumen': 'Lumen',
        'Niagara': 'Niagara',
        'Tutorial': 'æ•™ç¨‹',
        'Guide': 'æŒ‡å—',
        'Release': 'å‘å¸ƒ',
        'Update': 'æ›´æ–°',
        'Deep Learning': 'æ·±åº¦å­¦ä¹ ',
        'Machine Learning': 'æœºå™¨å­¦ä¹ ',
        'Neural': 'ç¥ç»ç½‘ç»œ',
        'Rendering': 'æ¸²æŸ“',
        'Ray Tracing': 'å…‰çº¿è¿½è¸ª',
        'Global Illumination': 'å…¨å±€å…‰ç…§'
    }
    
    chinese_title = title
    for en, cn in translations.items():
        chinese_title = chinese_title.replace(en, cn)
    
    # å„åˆ†ç±»åˆ†ææ¨¡æ¿
    category_templates = {
        "ue": {
            "summary": f"æœ¬æ–‡ä»‹ç»äº†è™šå¹»å¼•æ“ç›¸å…³çš„æœ€æ–°æŠ€æœ¯è¿›å±•ã€‚{summary[:200] if summary else 'è¯¦ç»†æ¢è®¨äº†UE5å¼•æ“çš„æ–°åŠŸèƒ½å’Œä¼˜åŒ–æŠ€å·§ã€‚'}",
            "technologies": ["è™šå¹»å¼•æ“5", "æ¸²æŸ“ä¼˜åŒ–", "æ¸¸æˆå¼€å‘", "Niagaraç²’å­ç³»ç»Ÿ"],
            "analysis": f"è™šå¹»å¼•æ“ä½œä¸ºè¡Œä¸šä¸»æµæ¸¸æˆå¼•æ“ï¼ŒæŒç»­åœ¨æ¸²æŸ“æŠ€æœ¯ã€å·¥å…·é“¾å’Œå·¥ä½œæµç¨‹ä¸Šåˆ›æ–°ã€‚{summary[:150] if summary else 'æœ¬æ–‡æ¶‰åŠçš„æŠ€æœ¯æ–¹æ¡ˆå¯¹æ¸¸æˆå¼€å‘è€…å…·æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚'}",
            "audience": "ä¸­çº§UEå¼€å‘è€…",
            "difficulty": "ä¸­ç­‰"
        },
        "ta": {
            "summary": f"æœ¬æ–‡æ¢è®¨äº†æŠ€æœ¯ç¾æœ¯é¢†åŸŸçš„å®ç”¨æŠ€å·§ã€‚{summary[:200] if summary else 'åˆ†äº«äº†TAå·¥ä½œä¸­çš„æœ€ä½³å®è·µã€‚'}",
            "technologies": ["æŠ€æœ¯ç¾æœ¯", "Shaderå¼€å‘", "æè´¨ç³»ç»Ÿ", "å·¥å…·å¼€å‘"],
            "analysis": f"æŠ€æœ¯ç¾æœ¯æ˜¯è¿æ¥ç¨‹åºå’Œç¾æœ¯çš„æ¡¥æ¢ã€‚{summary[:150] if summary else 'æœ¬æ–‡ä»‹ç»çš„æ–¹æ³•å¯ä»¥å¸®åŠ©TAå›¢é˜Ÿæ›´é«˜æ•ˆåœ°å®Œæˆå·¥ä½œã€‚'}",
            "audience": "æŠ€æœ¯ç¾æœ¯å¸ˆ",
            "difficulty": "ä¸­ç­‰"
        },
        "ta-render": {
            "summary": f"æœ¬æ–‡åˆ†äº«äº†ç‰¹æ•ˆåˆ¶ä½œçš„å®æˆ˜ç»éªŒã€‚{summary[:200] if summary else 'å±•ç¤ºäº†æ¸²æŸ“å’Œç‰¹æ•ˆä¼˜åŒ–çš„å…·ä½“æ¡ˆä¾‹ã€‚'}",
            "technologies": ["è§†è§‰ç‰¹æ•ˆ", "æ¸²æŸ“ä¼˜åŒ–", "å®æ—¶æ¸²æŸ“", "Niagara"],
            "analysis": f"è§†è§‰ç‰¹æ•ˆæ˜¯æå‡æ¸¸æˆæ²‰æµ¸æ„Ÿçš„å…³é”®ã€‚{summary[:150] if summary else 'æœ¬æ–‡ä»‹ç»çš„æŠ€å·§å¯ä»¥å¸®åŠ©åœ¨ä¿æŒé«˜è´¨é‡çš„åŒæ—¶æ§åˆ¶å¥½æ€§èƒ½å¼€é”€ã€‚'}",
            "audience": "ç‰¹æ•ˆå¸ˆ",
            "difficulty": "ä¸­ç­‰"
        },
        "render": {
            "summary": f"æœ¬æ–‡æ·±å…¥æ¢è®¨äº†å®æ—¶æ¸²æŸ“æŠ€æœ¯çš„æœ€æ–°è¿›å±•ã€‚{summary[:200] if summary else 'æ¶µç›–äº†å›¾å½¢å­¦ç®—æ³•å’Œæ¸²æŸ“ç®¡çº¿çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚'}",
            "technologies": ["å®æ—¶æ¸²æŸ“", "å›¾å½¢å­¦ç®—æ³•", "å…‰çº¿è¿½è¸ª", "PBRæè´¨"],
            "analysis": f"å®æ—¶æ¸²æŸ“æŠ€æœ¯æ˜¯æ¸¸æˆå’Œå½±è§†è¡Œä¸šçš„æ ¸å¿ƒã€‚{summary[:150] if summary else 'æœ¬æ–‡æ¶‰åŠçš„æŠ€æœ¯æ–¹æ¡ˆä»£è¡¨äº†å½“å‰å›¾å½¢å­¦é¢†åŸŸçš„å‰æ²¿æ–¹å‘ã€‚'}",
            "audience": "æ¸²æŸ“å·¥ç¨‹å¸ˆ",
            "difficulty": "å›°éš¾"
        },
        "ai": {
            "summary": f"æœ¬æ–‡ä»‹ç»äº†AIæŠ€æœ¯åœ¨æ¸¸æˆå¼€å‘ä¸­çš„æœ€æ–°åº”ç”¨ã€‚{summary[:200] if summary else 'æ¢è®¨äº†æœºå™¨å­¦ä¹ å’Œç¥ç»ç½‘ç»œåœ¨å®æ—¶æ¸²æŸ“ä¸­çš„åˆ›æ–°åº”ç”¨ã€‚'}",
            "technologies": ["æœºå™¨å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "ç”Ÿæˆå¼AI", "AIè¾…åŠ©å¼€å‘"],
            "analysis": f"AIæ­£åœ¨æ·±åˆ»æ”¹å˜æ¸¸æˆå¼€å‘çš„å·¥ä½œæµç¨‹ã€‚{summary[:150] if summary else 'æœ¬æ–‡å±•ç¤ºçš„æŠ€æœ¯ä»£è¡¨äº†AIä¸æ¸¸æˆç»“åˆçš„æœ€æ–°è¶‹åŠ¿ã€‚'}",
            "audience": "AIå·¥ç¨‹å¸ˆ/æŠ€æœ¯ç¾æœ¯",
            "difficulty": "å›°éš¾"
        }
    }
    
    config = category_templates.get(category, category_templates["ta"])
    
    return {
        "chinese_title": chinese_title,
        "technical_summary": config["summary"],
        "key_technologies": config["technologies"],
        "technical_analysis": config["analysis"],
        "practical_value": "æå‡å·¥ä½œæ•ˆç‡ï¼Œä¼˜åŒ–é¡¹ç›®è´¨é‡",
        "related_topics": ["ç›¸å…³æŠ€æœ¯", "æœ€ä½³å®è·µ"],
        "target_audience": config["audience"],
        "implementation_difficulty": config["difficulty"]
    }

def generate_content_html(article, analysis):
    """ç”Ÿæˆæ–‡ç« HTML"""
    title = analysis['chinese_title']
    summary = analysis['technical_summary']
    tech_analysis = analysis['technical_analysis']
    technologies = analysis['key_technologies']
    link = article.get('link', '')
    published = article.get('published', datetime.now().strftime('%Y-%m-%d'))[:10]
    source = article.get('source_name', 'æœªçŸ¥æ¥æº')
    category = article.get('category', 'ta')
    
    config = CATEGORY_CONFIG.get(category, CATEGORY_CONFIG['ta'])
    tag_class = f"tag-{category}"
    
    tech_tags = ''.join([f'<span class="{tag_class} px-3 py-1 rounded-full text-sm">{tech}</span>' for tech in technologies])
    
    html = f'''<div class="article-content">
    <div class="flex flex-wrap items-center gap-3 mb-6">
        <span class="{tag_class} px-3 py-1 rounded-full text-sm">{config['name']}</span>
        <span class="text-gray-500">{published}</span>
        <span class="text-gray-500">â€¢</span>
        <span class="text-gray-500">{analysis['target_audience']}</span>
    </div>
    <h1>{title}</h1>
    <p class="text-xl text-gray-300 mb-6">{summary}</p>
    <div class="source-box">
        <div class="flex items-center gap-2 mb-2">
            <svg class="w-4 h-4 text-neon-amber" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13.828 10.172a4 4 0 00-5.656 0l-4 4a4 4 0 105.656 5.656l1.102-1.101m-.758-4.899a4 4 0 005.656 0l4-4a4 4 0 00-5.656-5.656l-1.1 1.1"></path>
            </svg>
            <span class="text-neon-amber font-medium">åŸæ–‡é“¾æ¥</span>
        </div>
        <div class="text-sm text-gray-400">
            <div>â€¢ <a href="{link}" target="_blank" class="text-neon-blue hover:underline">{source} - æŸ¥çœ‹å®Œæ•´åŸæ–‡</a></div>
        </div>
    </div>
    <div class="tech-analysis-box" style="border-color: {config['color']}40;">
        <div class="flex items-center gap-2 mb-4">
            <span class="text-lg font-semibold" style="color: {config['color']}">ğŸ”¬ æŠ€æœ¯åˆ†æ</span>
        </div>
        <p class="mb-0 text-gray-300 leading-relaxed">{tech_analysis}</p>
    </div>
    <h2>ğŸ¯ æ ¸å¿ƒæŠ€æœ¯ç‚¹</h2>
    <div class="flex flex-wrap gap-2 mb-6">{tech_tags}</div>
    <div class="bg-dark-700/50 rounded-xl p-6 mt-8 border-l-4" style="border-color: {config['color']}">
        <p class="mb-0 text-gray-400">
            <strong style="color: {config['color']}">ğŸ’¡ æç¤º:</strong> 
            æœ¬æ–‡ä¸ºè‡ªåŠ¨æŠ“å–ç”Ÿæˆçš„ä¸­æ–‡æ‘˜è¦ã€‚å¦‚éœ€å®Œæ•´æŠ€æœ¯ç»†èŠ‚ï¼Œè¯·ç‚¹å‡»ä¸Šæ–¹åŸæ–‡é“¾æ¥ã€‚
        </p>
    </div>
</div>'''
    return html

def fetch_rss_source(source, max_articles=5):
    """æŠ“å–RSSæº"""
    articles = []
    try:
        print(f"  æŠ“å–: {source['name']}...")
        feed = feedparser.parse(source['url'])
        count = 0
        
        for entry in feed.entries[:max_articles * 2]:  # å¤šæŠ“ä¸€äº›ç”¨äºè¿‡æ»¤
            if count >= max_articles:
                break
                
            article_id = generate_article_id(entry.get('link', ''))
            published = entry.get('published', '') or entry.get('updated', datetime.now().strftime('%Y-%m-%d'))
            summary = entry.get('summary', '')
            if not summary and 'content' in entry:
                summary = entry.content[0].value
            
            article = {
                'id': article_id,
                'title': entry.get('title', 'æ— æ ‡é¢˜'),
                'link': entry.get('link', ''),
                'summary': clean_html(summary),
                'published': published,
                'source_name': source['name'],
                'category': source['category'],
                'fetched_at': datetime.now().isoformat()
            }
            articles.append(article)
            count += 1
        
        print(f"  âœ“ {len(articles)} ç¯‡")
    except Exception as e:
        print(f"  âœ— å¤±è´¥: {e}")
    
    return articles

def update_knowledge_base(new_articles):
    """æ›´æ–°çŸ¥è¯†åº“"""
    with open(KB_FILE, 'r', encoding='utf-8') as f:
        content = f.read()
    
    match = re.search(r'articles:\s*({.*?}),\s*currentCategory', content, re.DOTALL)
    if not match:
        print("âŒ æ— æ³•è§£æçŸ¥è¯†åº“")
        return False
    
    articles = json.loads(match.group(1))
    
    # æ·»åŠ æ–°æ–‡ç« 
    for article_id, article_data in new_articles.items():
        if article_id not in articles:
            article = article_data['article']
            analysis = article_data['analysis']
            config = CATEGORY_CONFIG.get(article['category'], CATEGORY_CONFIG['ta'])
            
            articles[article_id] = {
                'title': analysis['chinese_title'],
                'category': article['category'],
                'tags': analysis['key_technologies'],
                'date': article.get('published', datetime.now().strftime('%Y-%m-%d'))[:10],
                'author': f"{article['source_name']} / è‡ªåŠ¨æ‘˜è¦",
                'readTime': '5åˆ†é’Ÿ',
                'difficulty': analysis['implementation_difficulty'],
                'content': generate_content_html(article, analysis)
            }
            print(f"  + æ·»åŠ : {analysis['chinese_title'][:40]}...")
    
    # é‡æ–°æ„å»ºçŸ¥è¯†åº“
    meta = {
        "lastUpdated": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "totalArticles": len(articles),
        "autoGenerated": True,
        "version": "4.1-enhanced"
    }
    
    js_content = f'''// Realtime Tech Knowledge Base - Enhanced Auto Generated
const knowledgeBase = {{
    meta: {json.dumps(meta, indent=4)},
    articles: {json.dumps(articles, ensure_ascii=False, indent=4)},
    currentCategory: 'home',
    getArticle(id) {{ return this.articles[id] || {{ title: 'æ–‡ç« ä¸å­˜åœ¨', content: '<div class="text-center py-12"><h2>æ‰¾ä¸åˆ°è¯¥æ–‡ç« </h2></div>' }}; }},
    getArticlesByCategory(category) {{ return Object.entries(this.articles).filter(([id, a]) => a.category === category).map(([id, a]) => ({{ id, ...a }})); }}
}};
function showPage(pageId) {{ document.querySelectorAll('.page').forEach(p => p.classList.remove('active')); const t = document.getElementById('page-' + pageId); if (t) {{ if (['ue','ta','render','ta-render','ai'].includes(pageId)) loadCategoryPage(pageId); t.classList.add('active'); }} if (pageId !== 'article') knowledgeBase.currentCategory = pageId; document.getElementById('mobile-menu').classList.add('hidden'); window.scrollTo(0, 0); }}
function loadCategoryPage(category) {{ const page = document.getElementById('page-' + category); const articles = knowledgeBase.getArticlesByCategory(category); const names = {{'ue':'Unreal Engine','ta':'æŠ€æœ¯ç¾æœ¯','render':'å®æ—¶æ¸²æŸ“','ta-render':'TAæ¸²æŸ“ä¸“æ ','ai':'AIæŠ€æœ¯'}}; const classes = {{'ue':'tag-ue','ta':'tag-ta','render':'tag-render','ta-render':'tag-ta-render','ai':'tag-ai'}}; let html = articles.map(a => `<div onclick="showArticle('${{a.id}}')" class="glass-panel rounded-2xl p-6 card-hover cursor-pointer"><div class="flex items-center gap-2 mb-3"><span class="${{classes[category]}} px-2 py-1 rounded text-xs">${{a.tags[0]}}</span><span class="text-gray-500 text-xs">${{a.readTime}}</span><span class="text-gray-500 text-xs">â€¢</span><span class="text-gray-500 text-xs">${{a.difficulty}}</span></div><h3 class="text-xl font-semibold text-white mb-2">${{a.title}}</h3><p class="text-gray-400 text-sm">${{a.author}} Â· ${{a.date}}</p></div>`).join(''); if (articles.length === 0) html = '<div class="glass-panel rounded-2xl p-12 text-center"><h3>è¯¥åˆ†ç±»æš‚æ— æ–‡ç« </h3></div>'; page.innerHTML = `<div class="py-12 px-6"><div class="max-w-7xl mx-auto"><div class="flex items-center gap-4 mb-8"><button onclick="showPage('home')" class="flex items-center gap-2 px-4 py-2 rounded-lg glass-panel hover:bg-white/5"><i data-lucide="home" class="w-5 h-5"></i><span>å›åˆ°ä¸»é¡µ</span></button><div><h2 class="text-3xl font-bold ${{category === 'ta-render' ? 'text-neon-green' : 'text-white'}}">${{names[category]}}</h2><p class="text-gray-500">å…± ${{articles.length}} ç¯‡æŠ€æœ¯æ–‡ç« </p></div></div><div class="grid grid-cols-1 md:grid-cols-2 gap-6">${{html}}</div></div></div>`; }}
function showArticle(id) {{ const a = knowledgeBase.getArticle(id); const p = document.getElementById('page-article'); p.innerHTML = `<div class="py-12 px-6"><div class="max-w-4xl mx-auto"><button onclick="backToCategory()" class="flex items-center gap-2 text-gray-400 hover:text-white mb-6"><i data-lucide="arrow-left" class="w-5 h-5"></i><span>è¿”å›åˆ†ç±»</span></button><div class="glass-panel rounded-3xl p-8 md:p-12">${{a.content}}</div></div></div>`; showPage('article'); if (typeof lucide !== 'undefined') lucide.createIcons(); }}
function backToCategory() {{ if (knowledgeBase.currentCategory && knowledgeBase.currentCategory !== 'home') showPage(knowledgeBase.currentCategory); else showPage('home'); }}
function toggleMobileMenu() {{ document.getElementById('mobile-menu').classList.toggle('hidden'); }}
document.addEventListener('DOMContentLoaded', function() {{ if (typeof lucide !== 'undefined') lucide.createIcons(); const t = document.getElementById('last-update-time'); if (t) t.textContent = knowledgeBase.meta.lastUpdated; }});
'''
    
    with open(KB_FILE, 'w', encoding='utf-8') as f:
        f.write(js_content)
    
    return True

def main():
    print("="*60)
    print("ğŸ¤– Realtime Tech å¢å¼ºç‰ˆå…¨è‡ªåŠ¨æ›´æ–°")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    config = load_sources()
    sources = config.get('sources', [])
    settings = config.get('settings', {})
    
    max_per_source = settings.get('max_articles_per_source', 5)
    min_per_category = settings.get('min_articles_per_category', 2)
    fetch_days = settings.get('fetch_days_back', 3)
    
    existing_articles = load_existing_articles()
    existing_ids = set(existing_articles.keys())
    print(f"\nç°æœ‰æ–‡ç« : {len(existing_articles)} ç¯‡")
    
    # æŒ‰åˆ†ç±»åˆ†ç»„æŠ“å–
    category_articles = {cat: [] for cat in CATEGORY_CONFIG.keys()}
    
    for source in sources:
        if not source.get('enabled', True):
            continue
        
        fetched = fetch_rss_source(source, max_per_source)
        
        for article in fetched:
            if should_include_article(article, settings, existing_ids):
                if is_recent_article(article, fetch_days):
                    cat = article['category']
                    if cat in category_articles:
                        category_articles[cat].append(article)
                    else:
                        category_articles['ta'].append(article)
    
    # ç»Ÿè®¡å„åˆ†ç±»æ–‡ç« æ•°
    print("\nğŸ“Š å„åˆ†ç±»æ–°æ–‡ç« ç»Ÿè®¡:")
    for cat, articles in category_articles.items():
        print(f"  {CATEGORY_CONFIG[cat]['name']}: {len(articles)}ç¯‡")
    
    # ç¡®ä¿æ¯ä¸ªåˆ†ç±»è‡³å°‘æœ‰min_per_categoryç¯‡æ–‡ç« 
    final_articles = []
    for cat, articles in category_articles.items():
        count = len(articles)
        if count >= min_per_category:
            # å¦‚æœè¶…è¿‡ï¼ŒæŒ‰æ—¶é—´æ’åºå–æœ€æ–°çš„
            sorted_articles = sorted(articles, key=lambda x: x.get('published', ''), reverse=True)
            final_articles.extend(sorted_articles[:min_per_category + 2])  # å¤šç•™2ç¯‡å†—ä½™
        else:
            # å¦‚æœä¸è¶³ï¼Œå…¨éƒ¨ä¿ç•™ï¼ˆåé¢ä¼šæç¤ºï¼‰
            final_articles.extend(articles)
    
    print(f"\nğŸ“ æœ€ç»ˆé€‰å–: {len(final_articles)} ç¯‡")
    
    # åˆ†ç±»ç»Ÿè®¡
    final_by_category = {cat: 0 for cat in CATEGORY_CONFIG.keys()}
    for article in final_articles:
        cat = article.get('category', 'ta')
        if cat in final_by_category:
            final_by_category[cat] += 1
    
    print("\nğŸ“ˆ å„åˆ†ç±»æœ€ç»ˆæ•°é‡:")
    for cat, count in final_by_category.items():
        status = "âœ…" if count >= min_per_category else "âš ï¸"
        print(f"  {status} {CATEGORY_CONFIG[cat]['name']}: {count}ç¯‡ (ç›®æ ‡: {min_per_category}ç¯‡)")
    
    if final_articles:
        # ç”Ÿæˆåˆ†æå’Œæ›´æ–°çŸ¥è¯†åº“
        processed = {}
        for article in final_articles:
            print(f"\nå¤„ç†: {article['title'][:50]}...")
            analysis = generate_analysis(article, article['category'])
            processed[article['id']] = {
                'article': article,
                'analysis': analysis
            }
            existing_articles[article['id']] = article
        
        print("\nğŸ’¾ æ›´æ–°çŸ¥è¯†åº“...")
        if update_knowledge_base(processed):
            save_articles(existing_articles)
            print(f"\nâœ… æˆåŠŸæ·»åŠ  {len(processed)} ç¯‡æ–°æ–‡ç« ")
            
            # æ›´æ–°ç»Ÿè®¡
            print("\nğŸ“Š æ›´æ–°åå„åˆ†ç±»ç»Ÿè®¡:")
            with open(KB_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            match = re.search(r'articles:\s*({.*?}),\s*currentCategory', content, re.DOTALL)
            if match:
                all_articles = json.loads(match.group(1))
                cat_counts = {cat: 0 for cat in CATEGORY_CONFIG.keys()}
                for aid, article in all_articles.items():
                    cat = article.get('category', 'ta')
                    if cat in cat_counts:
                        cat_counts[cat] += 1
                
                for cat, count in cat_counts.items():
                    print(f"  {CATEGORY_CONFIG[cat]['name']}: {count}ç¯‡")
        else:
            print("âŒ æ›´æ–°å¤±è´¥")
    else:
        print("\nâœ“ æ²¡æœ‰æ–°æ–‡ç« ")
    
    print("="*60)

if __name__ == "__main__":
    main()
