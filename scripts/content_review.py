#!/usr/bin/env python3
"""
Realtime Tech Library - å†…å®¹è´¨é‡Reviewå·¥å…·
æ¯3å¤©è¿è¡Œä¸€æ¬¡ï¼Œæ£€æŸ¥ï¼š
1. æ–‡ç« å‹˜è¯¯
2. é˜…è¯»åŸæ–‡é“¾æ¥æœ‰æ•ˆæ€§
3. å†…å®¹è´¨é‡è¯„åˆ†
4. ä¼˜è´¨å†…å®¹æ ‡è®°
"""

import json
import os
import re
from datetime import datetime, timedelta

WORKSPACE = "."
ARTICLES_FILE = f"{WORKSPACE}/data/articles.json"
KB_FILE = f"{WORKSPACE}/knowledge-base.js"
REVIEW_LOG = f"{WORKSPACE}/data/review_log.json"

# ä¼˜è´¨æ¥æºç™½åå•
QUALITY_SOURCES = [
    "Unreal Engine å®˜æ–¹åšå®¢",
    "Epic Games",
    "NVIDIA",
    "80 Level",
    "Gamasutra",
    "GDC Vault",
    "SIGGRAPH",
    "SideFX Houdini",
    "Realtime VFX",
    "ArtStation Magazine",
    "CG Channel"
]

# ä¼˜è´¨å…³é”®è¯
QUALITY_KEYWORDS = [
    "SIGGRAPH", "GDC", "UE5", "Unreal Engine 5", "Nanite", "Lumen", "Niagara",
    "Houdini", "Ray Tracing", "Global Illumination", "PBR", "VFX", " Niagara"
]

def load_json(filepath):
    if os.path.exists(filepath):
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_json(data, filepath):
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def check_source_quality(source_name):
    """æ£€æŸ¥æ¥æºæ˜¯å¦ä¸ºä¼˜è´¨æ¥æº"""
    for quality_source in QUALITY_SOURCES:
        if quality_source.lower() in source_name.lower():
            return True
    return False

def check_content_quality(article):
    """æ£€æŸ¥å†…å®¹è´¨é‡"""
    title = article.get('title', '')
    summary = article.get('summary', '')
    
    score = 0
    reasons = []
    
    # æ£€æŸ¥ä¼˜è´¨å…³é”®è¯
    for keyword in QUALITY_KEYWORDS:
        if keyword.lower() in title.lower() or keyword.lower() in summary.lower():
            score += 10
            reasons.append(f"åŒ…å«ä¼˜è´¨å…³é”®è¯: {keyword}")
    
    # æ£€æŸ¥æ¥æºè´¨é‡
    if check_source_quality(article.get('source_name', '')):
        score += 20
        reasons.append("æ¥æºä¸ºä¼˜è´¨æŠ€æœ¯ç«™ç‚¹")
    
    # æ£€æŸ¥æ‘˜è¦é•¿åº¦ï¼ˆæœ‰æ‘˜è¦é€šå¸¸è´¨é‡æ›´é«˜ï¼‰
    if len(summary) > 100:
        score += 10
        reasons.append("æ‘˜è¦å†…å®¹å®Œæ•´")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰UEç›¸å…³å†…å®¹
    if any(kw in title.lower() for kw in ['unreal', 'ue5', 'niagara', 'lumen']):
        score += 15
        reasons.append("Unreal Engineç›¸å…³å†…å®¹")
    
    # åˆ¤æ–­è´¨é‡ç­‰çº§
    if score >= 40:
        level = "ä¼˜è´¨"
    elif score >= 25:
        level = "è‰¯å¥½"
    elif score >= 10:
        level = "ä¸€èˆ¬"
    else:
        level = "éœ€æ”¹è¿›"
    
    return {
        "score": score,
        "level": level,
        "reasons": reasons
    }

def check_link_validity(article):
    """æ£€æŸ¥åŸæ–‡é“¾æ¥ï¼ˆæ ‡è®°éœ€è¦æ£€æŸ¥çš„é“¾æ¥ï¼‰"""
    link = article.get('link', '')
    
    # æ£€æŸ¥é“¾æ¥æ ¼å¼
    if not link.startswith(('http://', 'https://')):
        return {"valid": False, "issue": "é“¾æ¥æ ¼å¼ä¸æ­£ç¡®"}
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå¸¸è§æ— æ•ˆé“¾æ¥
    invalid_patterns = ['example.com', 'localhost', '127.0.0.1']
    for pattern in invalid_patterns:
        if pattern in link:
            return {"valid": False, "issue": f"åŒ…å«æ— æ•ˆåŸŸå: {pattern}"}
    
    return {"valid": True, "issue": None}

def review_article(article_id, article):
    """Reviewå•ç¯‡æ–‡ç« """
    print(f"\nğŸ“„ Review: {article['title'][:50]}...")
    
    # å†…å®¹è´¨é‡æ£€æŸ¥
    quality = check_content_quality(article)
    print(f"   è´¨é‡è¯„åˆ†: {quality['score']} - {quality['level']}")
    for reason in quality['reasons'][:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªåŸå› 
        print(f"   âœ“ {reason}")
    
    # é“¾æ¥æœ‰æ•ˆæ€§æ£€æŸ¥
    link_check = check_link_validity(article)
    if not link_check['valid']:
        print(f"   âš ï¸ é“¾æ¥é—®é¢˜: {link_check['issue']}")
    
    return {
        "article_id": article_id,
        "title": article['title'],
        "quality_score": quality['score'],
        "quality_level": quality['level'],
        "link_valid": link_check['valid'],
        "link_issue": link_check['issue'],
        "reviewed_at": datetime.now().isoformat()
    }

def main():
    print("="*60)
    print("ğŸ” Realtime Tech Library - å†…å®¹è´¨é‡Review")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    # åŠ è½½æ–‡ç« 
    articles = load_json(ARTICLES_FILE)
    print(f"\nğŸ“š å…± {len(articles)} ç¯‡æ–‡ç« éœ€è¦Review")
    
    # Reviewæ¯ç¯‡æ–‡ç« 
    review_results = []
    quality_stats = {"ä¼˜è´¨": 0, "è‰¯å¥½": 0, "ä¸€èˆ¬": 0, "éœ€æ”¹è¿›": 0}
    
    for article_id, article in articles.items():
        result = review_article(article_id, article)
        review_results.append(result)
        quality_stats[result['quality_level']] += 1
    
    # ç»Ÿè®¡
    print("\n" + "="*60)
    print("ğŸ“Š Reviewç»Ÿè®¡")
    print("="*60)
    for level, count in quality_stats.items():
        print(f"  {level}: {count}ç¯‡")
    
    # ä¿å­˜Reviewæ—¥å¿—
    review_log = {
        "review_date": datetime.now().isoformat(),
        "total_articles": len(articles),
        "quality_distribution": quality_stats,
        "results": review_results
    }
    save_json(review_log, REVIEW_LOG)
    print(f"\nğŸ’¾ Reviewæ—¥å¿—å·²ä¿å­˜: {REVIEW_LOG}")
    
    # æ ‡è®°ä¼˜è´¨æ–‡ç« 
    high_quality = [r for r in review_results if r['quality_level'] == 'ä¼˜è´¨']
    print(f"\nğŸ† ä¼˜è´¨æ–‡ç« : {len(high_quality)}ç¯‡")
    for item in high_quality[:5]:  # åªæ˜¾ç¤ºå‰5ç¯‡
        print(f"  â€¢ {item['title'][:40]}...")
    
    print("\nâœ… Reviewå®Œæˆ!")
    print("="*60)

if __name__ == "__main__":
    main()
